{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem-2: \n",
    "\n",
    "#### Trade Forecasting\n",
    "__Welcome to Antallagma__ - a digital exchange for trading goods. Antallagma started its operations 5 years back and has supported more than a million transactions till date. The Antallagma platform enables working of a traditional exchange on an online portal.\n",
    "\n",
    "On one hand, buyers make a bid at the value they are willing to buy (\"bid value‚Äù) and the quantity they are willing to buy. Sellers on the other hand, ask for an ask price and the quantity they are willing to sell. The portal matches the buyers and sellers in realtime to create trades. All trades are settled at the end of the day at the median price of all agreed trades.\n",
    "\n",
    "You are one of the traders on the exchange and can supply all the material being traded on the exchange. In order to improve your logistics, you want to predict the median trade prices and volumes for all the trades happening (at item level) on the exchange. You can then plan to use these predictions to create an optimized inventory strategy.\n",
    "\n",
    "You are expected to create trade forecasts for all items being traded on Antallagma along with the trade prices for a period of 6 months.\n",
    "\n",
    "__Evaluation Criteria:__\n",
    "Overall Error = Lambda1 x RMSE error of volumes + Lambda2 x RMSE error of prices Where Lambda1 and Lambda2 are normalising parameters\n",
    "\n",
    "__Description:__\n",
    "There were in-total of 1529 unique stocks in the data.\n",
    "The data is from jan-2014 to june-2016. Divide the data into train and test (Jan-2016 to June-2016). Build your models on train and present your final scores on test.\n",
    "Category_1, Category_2, Category_3 are Binary masked feature, Ordered Masked feature, Unordered Masked feature respectively.\n",
    "Price (Median Price at Sale on that day), Number_Of_Sales (Total Item Sold on that day) are two target variables.\n",
    "\n",
    "Students can use both machine learning and data driven models to solve this problem.\n",
    "\n",
    "__Important links:__\n",
    "* https://github.com/Prakashvanapalli/av_july_2017\n",
    "* https://datahaccurl\n",
    "* http://localhost:8080/words/top/2k.analyticsvidhya.com/contest/fractal-analytics-hiring-hackathon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Category_3</th>\n",
       "      <th>Category_2</th>\n",
       "      <th>Category_1</th>\n",
       "      <th>Price</th>\n",
       "      <th>Number_Of_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30495_20140101</th>\n",
       "      <td>30495</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90</td>\n",
       "      <td>165.123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30375_20140101</th>\n",
       "      <td>30375</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>307</td>\n",
       "      <td>68.666</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30011_20140101</th>\n",
       "      <td>30011</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67</td>\n",
       "      <td>253.314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30864_20140101</th>\n",
       "      <td>30864</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>315</td>\n",
       "      <td>223.122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30780_20140101</th>\n",
       "      <td>30780</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132</td>\n",
       "      <td>28.750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Item_ID    Datetime  Category_3  Category_2  Category_1  \\\n",
       "ID                                                                        \n",
       "30495_20140101    30495  2014-01-01           0         2.0          90   \n",
       "30375_20140101    30375  2014-01-01           0         2.0         307   \n",
       "30011_20140101    30011  2014-01-01           0         3.0          67   \n",
       "30864_20140101    30864  2014-01-01           0         2.0         315   \n",
       "30780_20140101    30780  2014-01-01           1         2.0         132   \n",
       "\n",
       "                  Price  Number_Of_Sales  \n",
       "ID                                        \n",
       "30495_20140101  165.123                1  \n",
       "30375_20140101   68.666                5  \n",
       "30011_20140101  253.314                2  \n",
       "30864_20140101  223.122                1  \n",
       "30780_20140101   28.750                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 881876 entries, 30495_20140101 to 30132_20160630\n",
      "Data columns (total 7 columns):\n",
      "Item_ID            881876 non-null int64\n",
      "Datetime           881876 non-null object\n",
      "Category_3         881876 non-null int64\n",
      "Category_2         790263 non-null float64\n",
      "Category_1         881876 non-null int64\n",
      "Price              881876 non-null float64\n",
      "Number_Of_Sales    881876 non-null int64\n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 53.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateTime_pd'] = pd.to_datetime(df['Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 881876 entries, 30495_20140101 to 30132_20160630\n",
      "Data columns (total 8 columns):\n",
      "Item_ID            881876 non-null int64\n",
      "Datetime           881876 non-null object\n",
      "Category_3         881876 non-null int64\n",
      "Category_2         790263 non-null float64\n",
      "Category_1         881876 non-null int64\n",
      "Price              881876 non-null float64\n",
      "Number_Of_Sales    881876 non-null int64\n",
      "DateTime_pd        881876 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(1)\n",
      "memory usage: 60.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    227166\n",
       "3.0    212388\n",
       "1.0    140098\n",
       "4.0    106903\n",
       "5.0    103708\n",
       "Name: Category_2, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 790263 entries, 30495_20140101 to 30305_20160630\n",
      "Data columns (total 7 columns):\n",
      "Item_ID            790263 non-null int64\n",
      "Category_3         790263 non-null int64\n",
      "Category_2         790263 non-null float64\n",
      "Category_1         790263 non-null int64\n",
      "Price              790263 non-null float64\n",
      "Number_Of_Sales    790263 non-null int64\n",
      "DateTime_pd        790263 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(4)\n",
      "memory usage: 48.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ndf.drop(['Datetime'], axis=1, inplace=True)\n",
    "ndf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_ml(df, features, target, model, test_size=0.01):\n",
    "    X = df[features].copy()\n",
    "    y = df[target].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=test_size, random_state=42)\n",
    "    model = model(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_test, y_pred\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2, mse, rmse\n",
    "\n",
    "def visualize(y_test, y_pred):\n",
    "    plt.figure(12,8)\n",
    "    plt.scatter(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['Category_1', 'Category_2', 'Category_3', 'Price']\n",
    "target = 'Number_Of_Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-649ff9228ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-b5ef60e4e8a8>\u001b[0m in \u001b[0;36mdo_ml\u001b[0;34m(df, features, target, model, test_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m      X, y, test_size=test_size, random_state=42)\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y_test, y_pred = do_ml(df, features, target, LinearRegression, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score = 0.011871\n",
      "Root Mean Square Error = 7437.914980\n"
     ]
    }
   ],
   "source": [
    "r2, mse, rmse = metrics(y_test, y_pred)\n",
    "print('R2 Score = %f' %r2) \n",
    "print('Root Mean Square Error = %f' %rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "30495_20140101    2014-01-01\n",
       "30375_20140101    2014-01-01\n",
       "30011_20140101    2014-01-01\n",
       "30864_20140101    2014-01-01\n",
       "30780_20140101    2014-01-01\n",
       "Name: Datetime, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Datetime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert input [ID\n30495_20140101   2014-01-01\n30375_20140101   2014-01-01\n30011_20140101   2014-01-01\n30864_20140101   2014-01-01\n30780_20140101   2014-01-01\n30927_20140101   2014-01-01\n31342_20140101   2014-01-01\n30540_20140101   2014-01-01\n29999_20140101   2014-01-01\n30068_20140101   2014-01-01\n30541_20140101   2014-01-01\n30602_20140101   2014-01-01\n30622_20140101   2014-01-01\n30825_20140101   2014-01-01\n31012_20140101   2014-01-01\n31062_20140101   2014-01-01\n29841_20140101   2014-01-01\n30903_20140101   2014-01-01\n31308_20140101   2014-01-01\n31288_20140101   2014-01-01\n30317_20140101   2014-01-01\n31193_20140101   2014-01-01\n30531_20140101   2014-01-01\n30933_20140101   2014-01-01\n30111_20140101   2014-01-01\n30835_20140101   2014-01-01\n30108_20140101   2014-01-01\n30995_20140101   2014-01-01\n31285_20140101   2014-01-01\n30093_20140101   2014-01-01\n                    ...    \n31051_20160630   2016-06-30\n29952_20160630   2016-06-30\n30720_20160630   2016-06-30\n30168_20160630   2016-06-30\n30232_20160630   2016-06-30\n30078_20160630   2016-06-30\n30570_20160630   2016-06-30\n30984_20160630   2016-06-30\n30830_20160630   2016-06-30\n30300_20160630   2016-06-30\n31216_20160630   2016-06-30\n30143_20160630   2016-06-30\n29930_20160630   2016-06-30\n30600_20160630   2016-06-30\n29923_20160630   2016-06-30\n30876_20160630   2016-06-30\n31007_20160630   2016-06-30\n30781_20160630   2016-06-30\n30286_20160630   2016-06-30\n30509_20160630   2016-06-30\n29835_20160630   2016-06-30\n29818_20160630   2016-06-30\n31034_20160630   2016-06-30\n31099_20160630   2016-06-30\n30047_20160630   2016-06-30\n31009_20160630   2016-06-30\n30807_20160630   2016-06-30\n30305_20160630   2016-06-30\n31036_20160630   2016-06-30\n30132_20160630   2016-06-30\nName: DateTime_pd, Length: 881876, dtype: datetime64[ns]] of type <class 'pandas.core.series.Series'> to Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-06c7eea8c3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DateTime_pd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.Timestamp.__new__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.convert_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert input [ID\n30495_20140101   2014-01-01\n30375_20140101   2014-01-01\n30011_20140101   2014-01-01\n30864_20140101   2014-01-01\n30780_20140101   2014-01-01\n30927_20140101   2014-01-01\n31342_20140101   2014-01-01\n30540_20140101   2014-01-01\n29999_20140101   2014-01-01\n30068_20140101   2014-01-01\n30541_20140101   2014-01-01\n30602_20140101   2014-01-01\n30622_20140101   2014-01-01\n30825_20140101   2014-01-01\n31012_20140101   2014-01-01\n31062_20140101   2014-01-01\n29841_20140101   2014-01-01\n30903_20140101   2014-01-01\n31308_20140101   2014-01-01\n31288_20140101   2014-01-01\n30317_20140101   2014-01-01\n31193_20140101   2014-01-01\n30531_20140101   2014-01-01\n30933_20140101   2014-01-01\n30111_20140101   2014-01-01\n30835_20140101   2014-01-01\n30108_20140101   2014-01-01\n30995_20140101   2014-01-01\n31285_20140101   2014-01-01\n30093_20140101   2014-01-01\n                    ...    \n31051_20160630   2016-06-30\n29952_20160630   2016-06-30\n30720_20160630   2016-06-30\n30168_20160630   2016-06-30\n30232_20160630   2016-06-30\n30078_20160630   2016-06-30\n30570_20160630   2016-06-30\n30984_20160630   2016-06-30\n30830_20160630   2016-06-30\n30300_20160630   2016-06-30\n31216_20160630   2016-06-30\n30143_20160630   2016-06-30\n29930_20160630   2016-06-30\n30600_20160630   2016-06-30\n29923_20160630   2016-06-30\n30876_20160630   2016-06-30\n31007_20160630   2016-06-30\n30781_20160630   2016-06-30\n30286_20160630   2016-06-30\n30509_20160630   2016-06-30\n29835_20160630   2016-06-30\n29818_20160630   2016-06-30\n31034_20160630   2016-06-30\n31099_20160630   2016-06-30\n30047_20160630   2016-06-30\n31009_20160630   2016-06-30\n30807_20160630   2016-06-30\n30305_20160630   2016-06-30\n31036_20160630   2016-06-30\n30132_20160630   2016-06-30\nName: DateTime_pd, Length: 881876, dtype: datetime64[ns]] of type <class 'pandas.core.series.Series'> to Timestamp"
     ]
    }
   ],
   "source": [
    "pd.Timestamp(df['DateTime_pd'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
